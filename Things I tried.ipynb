{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137375ca",
   "metadata": {},
   "source": [
    "# Here I will list the things that I tried but didn't end up working\n",
    "\n",
    "## Cleaning :\n",
    "  I used a few different methods of cleaning, with a bunch of types of dictionaries but non were able to filter the words as I wanted. So a lot I did manually. Also nltk.LancasterStemmer() did not work well for me as it cut off too many words till were they didn't make sense. \n",
    "  \n",
    " ## Topic modeling:\n",
    "  I tried every number of topics between 5 and 40. I also tried diffenrent values for the alpha parameter. Five topics gave the smalleset complexity score, as well as the best clustering in the t-SNE graph. It was also the only number that didn;t have any topics with less then 20 movies assigned to it. That being said the actual words assigned to each topic, looks better as you get more topics. I also tried taking out words based on topics that are assigned to the vast majority of movies, but that didn't seem to help any. I also used both count vector and tf_idf vector, but the tf_idf vector did not work well at all. \n",
    "  \n",
    "## Clustering:\n",
    " I tried all number of clusters between 5 and 30, and decided on 5 from the elbow method. I tried euclidean and cosine and pearson distince. But in order to measure I needed to use the sklearn kmean, which only uses euclidean, so that is what I used in my final results. Although I think that cosine might be the best. I also did Agglomerative clustering with professor Barsky's code, but I didn't manage to interpret those results. \n",
    " \n",
    " ## Recommender \n",
    " I used sklearn knn to bulild a move recommender based on the topic modeling. To test it I used the movieLens dataset here https://grouplens.org/datasets/movielens/25m/. For each user I found the overlap between movies rated by them, and movies I did topic modeling for. I then bulit a knn model for each user. I For the y values, I first used the numeric ratings the user gave which were between 1 and 5. I then made a scatter plot with how well the recommnder did vs how many movies I had in my dataset (in theory the more movies, the better knn should work). I did this for many different topic numbers, and it did not work well for any of them. \n",
    " \n",
    " I also bined the y vlaues so that they were 0 if the rating was less then 3.5, and 1 if it was more then 3.5. This gave better results, but still not very good. I also chnaged the split to be at 4, and this gave a lot better results, but there were also a lot less 1 vlalues, so the results are less significent. \n",
    " \n",
    " ## others:\n",
    " I made an unsorted heatmap of the movies based on there topic and there was no clear clusters. \n",
    " \n",
    " many of these results were saved in the pics folder. \n",
    " \n",
    " For comparing the three clustering that I did, there are some satistical methods to do that, but I did not manage to do them. So I only used SSE and heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b52240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
